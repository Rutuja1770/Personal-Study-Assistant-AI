# ğŸ§  Study Assistant AI (Offline & Free)

A personal **AI-powered Study Assistant** built using **Python, Streamlit, Ollama, and Vector Databases**.  
This assistant helps with **concept explanations, coding support, and interview preparation**, and works **fully offline** with **no API key or cost**.

---

## ğŸš€ Features

- ğŸ“˜ Explains **Machine Learning, AI, Python, SQL** concepts
- ğŸ§‘â€ğŸ’» Helps with **coding problems & debugging**
- ğŸ¯ Assists in **interview preparation**
- ğŸ“„ Upload study PDFs (notes, interview prep)
- ğŸ§  Semantic memory using embeddings
- ğŸ’¬ Chat with contextual awareness
- ğŸ¯ Interview mock mode
- ğŸ§¾ Chat history tracking
- ğŸ†“ 100% FREE & Offline (Ollama based)
- ğŸ§  Remembers previous questions using **vector memory (RAG)**
- ğŸ”Œ Runs **offline** using open-source LLMs via **Ollama**
- ğŸ’¸ **No API key, no billing, no quota**

---

## ğŸ›  Tech Stack

- **Python**
- **Streamlit** â€“ UI
- **Ollama** â€“ Local LLM (LLaMA 3 / Mistral)
- **SentenceTransformers** â€“ Embeddings
- **NumPy** â€“ Similarity search
- **PyMuPDF** â€“ PDF text extraction

---


## ğŸ“– How It Works (Workflow)

User uploads a study PDF

Text is extracted and split into chunks

Chunks are converted into embeddings

User asks a question

Relevant content is retrieved using similarity search

Context + question is sent to local LLM

AI generates an accurate response

Chat history is stored in session memory
---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Install Ollama
Download and install Ollama from:

## ğŸ¯ Interview Use Case

Explain concepts

Practice mock interviews

Answer questions from notes

Learn offline without API costs

## ğŸ”’ Privacy & Cost

No API keys

No internet required

Data never leaves local machine

Completely free

## ğŸ“Œ Future Enhancements

Answer evaluation in interview mode

Persistent vector database (FAISS / ChromaDB)

Voice input

Multi-PDF support

ğŸ§ª Example Questions to Ask

1.Explain overfitting in machine learning
2.Difference between list and tuple in Python
3.Give SQL interview questions
4.Debug this Python code
5.Explain bias vs variance

ğŸ§  Key Concepts Used

Prompt Engineering
Retrieval-Augmented Generation (RAG)
Vector Embeddings
Local LLM Inference
Modular AI System Design


ğŸ¯ Use Cases

â†’ Students learning ML & programming
â†’ Interview preparation
â†’ Offline AI assistant
â†’ Portfolio project

## ğŸ‘¤ Author

Rutuja Sangar
